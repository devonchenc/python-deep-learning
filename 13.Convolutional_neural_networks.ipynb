{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络（Convolutional Neural Network，CNN）是一种专门用来处理具有类似网格结构数据的神经网络。例如时间序列数据（时间轴上有规律地采样形成的一维网格）和图像数据（二维的像素网格）。因此它被广泛用于图像识别、语音识别等各种场合，在图像识别的比赛中，基于深度学习的方法几乎都以 CNN 为基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 整体结构\n",
    "\n",
    "之前介绍的神经网络中，相邻层的所有神经元之间都有连接，这称为全连接（Fully Connected）层或 Affine 层。全连接层后面跟着激活函数 ReLU 层（或者Sigmoid 层）。这里堆叠了4 层“Affine-ReLU”组合，然后第 5 层是全连接层，最后由 Softmax 层输出最终分类结果。\n",
    "\n",
    "![img](images/chapter13/fully_connected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 中新增了Convolution 层和Pooling 层。典型 CNN 的层连接顺序是“Convolution - ReLU -（Pooling）”（Pooling 层有时会被省略）。\n",
    "\n",
    "![img](images/chapter13/CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 卷积层\n",
    "\n",
    "## 2.1 全连接层存在的问题\n",
    "\n",
    "输入数据的形状被全连接层“忽视”了。例如，向全连接层输入图像数据时，需要将 3 维图像数据（宽、高和通道数）拉平为 1 维数据。实际上，前面使用的 MNIST 数据集的例子中，输入图像就是 1 通道、高 28 像素、长 28 像素的（1, 28, 28）形状，但却被排成 1 列，以 784 个数据的形式输入到全连接层中。\n",
    "\n",
    "图像的 3 维形状中含有重要的空间信息。例如，空间上邻近的像素为相似的值、RBG的各个通道之间分别有密切的关联性、相距较远的像素之间没有什么关联等，3 维形状中可能隐藏有值得提取的本质模式。但是，因为全连接层会忽视形状，将全部的输入数据作为相同的神经元（同一维度的神经元）处理，所以无法利用与形状相关的信息。\n",
    "\n",
    "而卷积层可以保持数据形状不变。当输入数据是图像时，卷积层会以 3 维数据的形式接收输入数据，并同样以 3 维数据的形式输出至下一层。因此，在 CNN 中，可以正确理解图像等具有形状的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 中将卷积层的输入输出数据称为特征图（feature map）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 卷积运算\n",
    "\n",
    "对于输入数据，卷积运算以一定间隔滑动卷积核（或称为滤波器）的窗口并应用。将各个位置上卷积核的元素和输入的对应元素相乘，然后再求和（有时将这个计算称为乘积累加运算）。然后，将这个结果保存到输出的对应位置。将这个过程在所有位置都进行一遍，就可以得到卷积运算的输出。假设用（height, width）表示数据和卷积核的形状，则下图中输入数据尺寸是(5, 5)，输出数据尺寸是(3, 3)，卷积核尺寸是(3, 3)，其数值为\n",
    "\n",
    "$$ \\Bigg(\n",
    "   \\begin{matrix}\n",
    "   0 & 1 & 2 \\\\\n",
    "   2 & 2 & 0 \\\\\n",
    "   0 & 1 & 2\n",
    "  \\end{matrix} \\Bigg)\n",
    "$$\n",
    "\n",
    "![img](images/chapter13/numerical_no_padding_no_strides.gif)\n",
    "\n",
    "令 $i$ 为输入数据尺寸，$k$ 为卷积核尺寸，$o$ 为输出数据尺寸，则有关系：\n",
    "\n",
    "$$ o = (i - k) + 1 $$\n",
    "\n",
    "在全连接的神经网络中，除了权重参数，还存在偏置。CNN 中，卷积核的参数就对应之前的权重。并且，CNN 中也存在偏置，偏置被加到应用了卷积核的所有元素上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 填充（padding）\n",
    "\n",
    "在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据（通常为 0），这称为**填充**（padding），是卷积运算中经常会用到的处理。在下图中，对大小为 (4, 4) 的输入数据应用了幅度为 1 的填充。通过填充，大小为 (4, 4) 的输入数据变成了 (6, 6) 的形状。然后应用大小为 (3, 3) 的卷积核，生成了大小为 (4, 4) 的输出数据。\n",
    "\n",
    "![img](images/chapter13/padding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令 $p$ 为填充幅度，则有关系\n",
    "\n",
    "$$ o = (i - k) + 2p + 1 $$\n",
    "\n",
    "下图中的示例中，$i=5, k =4, p =2$，因此 $o=6$\n",
    "\n",
    "![img](images/chapter13/arbitrary_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Padding\n",
    "\n",
    "一类特殊的填充作为称之为 same padding，即使得输出数据尺寸等于输入数据尺寸。令卷积核尺寸 $k$ 为奇数（$k = 2n+1$），填充幅度 $p = \\lfloor \\frac{k}{2} \\rfloor= n$，则有\n",
    "\n",
    "$$ o = (i - 2n - 1)+2n+1 = i $$\n",
    "\n",
    "下图中的示例中，$i=o=5, k = 3, p=1$\n",
    "\n",
    "![img](images/chapter13/same_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Padding\n",
    "\n",
    "另一类特殊的填充作为称之为 full padding，即使卷积核与数据刚相交时开始做卷积，因此填充幅度 $p = k - 1$，\n",
    "\n",
    "$$o = (i - k)+2(k-1)+1 = i +k-1$$\n",
    "\n",
    "下图中的示例中，$i=5, k = 3, p=2$，因此 $o=6$\n",
    "![img](images/chapter13/full_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 步幅\n",
    "\n",
    "应用卷积核的位置间隔称为**步幅**（stride）。之前的例子中步幅都是 1，如果将步幅设为 2，则如下图所示，应用卷积核的窗口的间隔变为 2 个元素。\n",
    "\n",
    "![img](images/chapter13/stride.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令 $i$ 为输入数据尺寸，$p$ 为填充幅度，$k$ 为卷积核尺寸，$s$ 为步幅大小，$o$ 为输出数据尺寸，则有：\n",
    "\n",
    "$$ o = \\lfloor \\frac{i + 2p -k}{s} \\rfloor + 1 $$\n",
    "\n",
    "下图中的示例中，$i=5, k=3, s=2, p=1$，因此 $o=3$\n",
    "\n",
    "![img](images/chapter13/padding_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 三维数据的卷积运算\n",
    "\n",
    "图像是三维数据，将其表示为多维数组时顺序为(channel, height, width)，例如通道数为 C、高度为 H、长度为 W 的数据的形状可以写成（C, H, W）。在进行卷积运算时，除了高、宽方向之外还需要处理通道方向。通道方向上有多个特征图时，会按通道进行输入数据和卷积核的卷积运算，并将结果相加，从而得到输出。需要注意的是，输入数据和卷积核的通道数要为相同的值。\n",
    "\n",
    "![img](images/chapter13/3D_conv_0.png)\n",
    "\n",
    "这里以 3 通道的数据为例，输入数据尺寸是(3, 5, 5)，卷积核尺寸为(3, 3, 3)，填充幅度为0，步幅为1，则输出数据尺寸为(2, 2)。\n",
    "\n",
    "![img](images/chapter13/3D_conv_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分步计算顺序如下所示：\n",
    "\n",
    "![img](images/chapter13/3D_conv_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要在通道方向上也拥有多个卷积运算的输出，就需要用到多个卷积核。如下图所示，通过应用 FN 个滤波器，输出特征图也生成了 FN 个。如果将这 FN 个特征图汇集在一起，就得到了形状为(FN, OH,OW) 的数据体。\n",
    "\n",
    "![img](images/chapter13/multi_channel_conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进一步完善包含偏置加法运算的卷积运算，如下图所示。卷积核输出结果的形状是(FN, OH,OW) ，偏置的形状是(FN, 1, 1)，这两个数据相加时，得益于 NumPy 的广播功能，按通道加上相同的偏置值。\n",
    "\n",
    "![img](images/chapter13/multi_channel_conv_with_bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 批处理\n",
    "\n",
    "之前的全连接神经网络的实现对应了批处理，通过批处理能够实现高效化的运算和学习时对应 mini-batch 的 SDG 算法。卷积运算也同样支持批处理。为此，需要将在各层间传递的数据保存为四维数据，按(batch_num, channel, height, width)的顺序保存数据。\n",
    "\n",
    "![img](images/chapter13/batch_conv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
