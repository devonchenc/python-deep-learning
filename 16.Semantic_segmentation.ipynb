{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 语义分割(Semantic Segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**语义分割** 通过对图像所有像素进行密集的推断来实现细粒度的预测，从而使每个像素都被标记为其封闭对象区域的类别。目前广泛应用于医学影像与无人驾驶等。\n",
    "\n",
    "下图分别为图像分类、目标检测、语义分割和实例分割的示例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/chapter16/object_recongnition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 语义分割评价指标\n",
    "\n",
    "- 像素精度（pixel accuracy），也是最简单的度量，为标记正确的像素占总像素的比例\n",
    "$$ \\text{pixel accuracy} = \\frac{\\sum_i n_{ii}}{\\sum_i{t_i}} $$\n",
    "\n",
    "\n",
    "- 平均精度（mean accuracy），为所有类被正确分类像素数比例的均值\n",
    "$$ \\text{mean accuracy} = \\frac{1}{C}\\sum_i \\frac{n_{ii}}{t_i} $$\n",
    "\n",
    "\n",
    "- 平均交并比（mean Intersection over Union，mean IU），计算预测像素和真实像素两个集合的交集和并集之比\n",
    "$$\\text{mean IU} = \\frac{1}{C}\\sum_i \\frac{n_{ii}}{t_i+\\sum_j n_{ji}-n_{ii}} $$\n",
    "\n",
    "\n",
    "- 频权 IU（Frequency Weighted IU，f.w.IU）\n",
    "$$\\text{f.w.IU} = {(\\sum_k t_k)}^{-1}\\sum_i \\frac{t_in_{ii}}{t_i+\\sum_j n_{ji}-n_{ii}}$$\n",
    "\n",
    "其中，$n_{ji}$ 代表第 $j$ 类被识别为第 $i$ 类的像素个数，$t_i$ 代表标签中第 $i$ 类的像素个数，$C$ 代表类别数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用的语义分割数据集\n",
    "\n",
    "- [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)\n",
    "\n",
    "      VOC 数据集不仅包含了目标检测任务，也包含了语义分割任务，数据集同样包含 20 类目标和 1 类背景。VOC 还提供了了算法精度排名\n",
    "\n",
    "[Leaderboard](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6)\n",
    "\n",
    "- [MS COCO](http://cocodataset.org/)\n",
    "\n",
    "\n",
    "- [Cityscapes](https://www.cityscapes-dataset.com/)\n",
    "       Cityscapes 数据集是 2016 年推出的用于自动驾驶环境下的图像分割数据集，可以评估视觉算法在城区场景语义理解方面的性能。Cityscapes 包含50个欧洲城市不同场景、不同背景、不同季节的街景的33类标注物体，图像分辨率较大（1024×2048）\n",
    "       \n",
    "       \n",
    "- [ADE20K_MIT](http://groups.csail.mit.edu/vision/datasets/ADE20K/)\n",
    "      ADE20K 是一个场景理解的数据集，它包含 151 类目标和 1 类背景，包括各种物体（人、汽车等）、场景（天空、路面等）。训练集包含 20,210 幅图像, 验证集包含 2,000 幅图像, 测试集暂未公开。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经典的语义分割网络模型有：\n",
    "\n",
    "- [**FCN**（2014）](https://arxiv.org/abs/1411.4038)\n",
    "- [DeepLabv1（2014）](https://arxiv.org/abs/1412.7062)\n",
    "- [CRF-RNN（2015）](https://arxiv.org/abs/1502.03240)\n",
    "- [**U-Net**（2015）](https://arxiv.org/abs/1505.04597)\n",
    "- [SegNet（2015）](https://arxiv.org/abs/1511.00561)\n",
    "- [DeepLabv2（2016）](https://arxiv.org/abs/1606.00915)\n",
    "- [FC-DenseNet（2016）](https://arxiv.org/abs/1611.09326)\n",
    "- [PSPNet（2016）](https://arxiv.org/abs/1612.01105)\n",
    "- [RefineNet（2017）](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_RefineNet_Multi-Path_Refinement_CVPR_2017_paper.pdf)\n",
    "- [TuSimple（2017）](https://arxiv.org/abs/1702.08502)\n",
    "- [**DeepLabv3**（2017）](https://arxiv.org/abs/1706.05587)\n",
    "- [**DeepLabv3+**（2018）](https://arxiv.org/abs/1802.02611)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. [FCN](https://arxiv.org/abs/1411.4038)\n",
    "\n",
    "经典的 CNN 模型在卷积层之后使用全连接层获得固定长度的特征向量进行分类所，由于全连接层必须是固定尺寸输入，导致整个网络的输入尺寸无法改变。FCN（Fully Convolutional Network）的作者 Jonathan Long 意识到了这一限制来自于网络最后的全连接层，于是将最后的全连接层改为 1×1 卷积层实现。\n",
    "\n",
    "下图中的猫, 输入经典 AlexNet 网络中，输出为长度 1000 的特征向量，向量中每个元素代表输入图像属于每一类的概率。其中在对应“tabby cat”这一类上数值最高，因此判定输入图像属于“tabby cat”类。\n",
    "\n",
    "如果将分类网络改成全卷积网络，则网络输出了一个低分辨率的类的热图（heatmap）。\n",
    "![img](images/chapter16/transform_fc_to_conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用**反卷积层**（Deconvolution Layer）对最后一个卷积层的特征图进行上采样，使它恢复到与输入图像相同的尺寸，从而可以对每个像素都产生一个分类输出。\n",
    "\n",
    "![img](images/chapter16/FCN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 反卷积\n",
    "\n",
    "反卷积（Deconvolution）这个概念容易引起误会，转置卷积（Transposed Convolution）是一个更为合适的叫法。\n",
    "\n",
    "例如，对于 4×4 的输入图像，使用 3×3 的卷积核对其进行卷积，步长为 1 ，没有填充（即$i=4, k=3, s=1, p=0$）。因此输出的图像尺寸为 2×2，如下图所示。\n",
    "\n",
    "![img](images/chapter16/no_padding_no_strides.gif)\n",
    "\n",
    "将输入图像展开为 16 维向量 $x$，将输出图像展开为 4 维向量 $y$，则卷积运算表示为 $y = Cx$，其中 $C$ 可以写为如下的稀疏矩阵\n",
    "\n",
    "$$ \n",
    "\\begin{equation}\n",
    "\\left(\n",
    "  \\begin{array}{ccccc}\n",
    "    w_{0,0} & w_{0,1} & w_{0,2} & 0 & w_{1,0} & w_{1,1} & w_{1,2} & 0 & w_{2,0} & w_{2,1} & w_{2,2} & 0 & 0 & 0 & 0 & 0\\\\\n",
    "    0 & w_{0,0} & w_{0,1} & w_{0,2} & 0 & w_{1,0} & w_{1,1} & w_{1,2} & 0 & w_{2,0} & w_{2,1} & w_{2,2} & 0 & 0 & 0 & 0\\\\\n",
    "    0 & 0 & 0 & 0 & w_{0,0} & w_{0,1} & w_{0,2} & 0 & w_{1,0} & w_{1,1} & w_{1,2} & 0 & w_{2,0} & w_{2,1} & w_{2,2} & 0\\\\\n",
    "    0 & 0 & 0 & 0 & 0 & w_{0,0} & w_{0,1} & w_{0,2} & 0 & w_{1,0} & w_{1,1} & w_{1,2} & 0 & w_{2,0} & w_{2,1} & w_{2,2}\\\\\n",
    "  \\end{array}\n",
    "\\right)\n",
    "\\end{equation}\n",
    " $$\n",
    " \n",
    "转置卷积运算则是在 2×2 图像上乘以 $C^T$，可以记作 $y'=C^Tx'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一个理解反卷积运算的方式是，使用一个低效的卷积运算来实现：在 2×2 图像应用  3×3 的卷积核，并且填充幅度为 2（$i'=2,k'=k,s'=1,p'=2$），如下图所示\n",
    "\n",
    "![img](images/chapter16/no_padding_no_strides_transposed.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 跳跃结构\n",
    "\n",
    "FCN 模型进一步采用了**跳跃结构**（skip architecture），使用了**融合**（fusion）策略将高层特征和低层特征进行相加来提高模型分割性能。网络分别采用了 3 种不同的结构，分别是 FCN-32s（32 倍上采样）、FCN-16s（16 倍上采样）和 FCN-8s（8 倍上采样）。 \n",
    "\n",
    "- FCN-32s\n",
    "      输入图像经过 CNN 不断的卷积和池化，得到 pool5 层输出的特征图（特征图宽高是原图的 1/32），将该特征图通过 32 倍的上采样（反卷积层）得到最后输出结果。\n",
    "\n",
    " \n",
    "- FCN-16s\n",
    "      将 pool5 的输出特征图进行 2 倍上采样，与 pool4 经过 1×1 卷积层后输出的特征图进行融合，然后将融合结果进行 16 倍的上采样得到最后输出结果。 \n",
    "\n",
    "- FCN-8s\n",
    "      将 pool5 和 pool4 的融合结果进行 2 倍的上采样，再与 pool3 经过 1×1 卷积层后输出的特征图进行融合，之后进行 8 倍的上采样得到最后输出结果。\n",
    "      \n",
    "![img](images/chapter16/FCN_combine_coarse_with_fine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三种网络结构实验结果表明，将高层特征与低层特征的融合能够明显提高像素点的分类精度\n",
    "![img](images/chapter16/FCN_result.png)\n",
    "\n",
    "|模型|Pixel Accuracy|Mean Pixel Accuracy|Mean IU|f.w.IU|\n",
    "|:----|:---:|:---:|:---:|:---:|\n",
    "|FCN-32s-fixed | 83.0| 59.7| 45.4| 72.0|\n",
    "|FCN-32s| 89.1| 73.3| 59.4| 81.4|\n",
    "|FCN-16s |90.0| 75.7| 62.4 | 83.0|\n",
    "|FCN-8s| **90.3** | **75.9** |**62.7** |**83.2**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCN 模型影响比较深远，不仅是深度学习模型在语义分割领域的首次成功应用。而且自从 FCN 提出后，一些经典的目标检测和识别模型都采用了 FCN 的概念，例如 Faster R-CNN 模型和 SSD 模型。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. U-Net\n",
    "\n",
    "U-Net 是典型的对称编码解码（Encoder-Decoder）结构，网络结构如下图所示，因为形似英文字母 U 所以被称为 U-Net。\n",
    "\n",
    "网络首先反复进行卷积和池化操作进行下采样，然后通过反卷积进行上采样，同时与此前的特征图进行通道融合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/chapter16/U-Net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图中蓝/白色框表示特征图，蓝色箭头表示 3×3 卷积，用于特征提取；灰色箭头表示 skip-connection，用于特征融合；红色箭头表示 2×2 最大池化；绿色箭头表示 2 倍上采样；青色箭头表示 1×1 卷积，用于输出结果。\n",
    "\n",
    "与 FCN 不同的是，FCN 中深层信息与浅层信息融合是通过对应像素相加的方式，而 U-Net 是通过通道拼接的方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 带孔卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "带孔卷积、空洞卷积或膨胀卷积（Dilated Convolution或Atrous Convolution）是在标准的卷积核里加入空洞，以此来增加卷积层的感受野。相比标准的卷积运算，带孔卷积多了一个超参数，称之为带孔率（dilation rate），记作 $d$，指的是卷积核内的间隔数量。标准的卷积运算中 $d=1$，带孔卷积中 $d>1$。\n",
    "\n",
    "带孔卷积卷积核的有效尺寸 $\\hat k$ 为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat k= k+(k-1)(d-1)$$\n",
    "\n",
    "输出图像尺寸记作 $o$，则有\n",
    "\n",
    "$$ o = \\lfloor \\frac{i + 2p -k-(k-1)(d-1)}{s} \\rfloor + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/chapter16/atrous_convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下图中的示例中，$i=7,k=3,d=2,s=1,p=0$，因此 $o=3$\n",
    "\n",
    "![img](images/chapter16/dilation_conv.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果多次叠加带孔率相同的卷积层的话，则会出现 Gridding 问题，如下图(a)，叠加了三层 $d=2$ 的 3×3 卷积层后，输入层中 $13\\times 13$ 大小的区域内仅有 $7\\times7$ 的像素对输出层有共享作用。可以通过叠加 $d=1$、$d=2$ 和 $d=3$ 解决这个问题，如下图(b)所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/chapter16/gridding_problem.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
