{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 语义分割(Semantic Segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**语义分割** 通过对图像所有像素进行密集的推断来实现细粒度的预测，从而使每个像素都被标记为其封闭对象区域的类别。\n",
    "\n",
    "下图分别为图像分类、目标检测、语义分割和实例分割。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/chapter16/object_recongnition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评价指标\n",
    "\n",
    "- 平均精度（Pixel Accuracy），也是最简单的度量，为标记正确的像素占总像素的比例\n",
    "$$ \\text{PA} = \\frac{\\sum_i n_{ii}}{\\sum_i{t_i}} $$\n",
    "\n",
    "\n",
    "- 平均像素精度（Mean Pixel Accuracy），为所有类被正确分类像素数比例的均值\n",
    "$$ \\text{MPA} = \\frac{1}{C}\\sum_i \\frac{n_{ii}}{t_i} $$\n",
    "\n",
    "\n",
    "- 交并比（Intersection over Union，IU），计算预测像素和真实像素两个集合的交集和并集之比\n",
    "$$\\text{IU} = \\frac{1}{C}\\sum_i \\frac{n_{ii}}{t_i+\\sum_j n_{ji}-n_{ii}} $$\n",
    "\n",
    "\n",
    "- 频权 IU（Frequency Weighted IU，FWIU）\n",
    "$$\\text{FWIU} = {(\\sum_k t_k)}^{-1}\\sum_i \\frac{t_in_{ii}}{t_i+\\sum_j n_{ji}-n_{ii}}$$\n",
    "\n",
    "其中，$n_{ji}$ 代表第 $j$ 类被识别为第 $i$ 类的像素个数，$t_i$ 代表标签中第 $i$ 类的像素个数，$C$ 代表类别数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用的语义分割数据集\n",
    "\n",
    "- [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)\n",
    "\n",
    "[Leaderboard](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6)\n",
    "\n",
    "- [MS COCO](http://cocodataset.org/)\n",
    "\n",
    "\n",
    "- [Cityscapes](https://www.cityscapes-dataset.com/)\n",
    "       Cityscapes 数据集是由奔驰主推，提供无人驾驶环境下的图像分割数据集，用于评估视觉算法在城区场景语义理解方面的性能。Cityscapes 包含50个欧洲城市不同场景、不同背景、不同季节的街景的33类标注物体\n",
    "       \n",
    "       \n",
    "- [ADE20K_MIT](http://groups.csail.mit.edu/vision/datasets/ADE20K/)\n",
    "      ADE20K 是一个场景理解的新的数据集，这个数据集是可以免费下载的。它包含151个类别（包括背景），包括各种物体（比如人、汽车等）、场景（天空、路面等）。训练集包含 20,210 幅图像, 验证集包含 2,000 幅图像, 测试集暂未公开。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. [FCN](https://arxiv.org/abs/1411.4038)\n",
    "\n",
    "FCN（Fully Convolutional Network）\n",
    "\n",
    "经典的 CNN 模型在卷积层之后使用全连接层获得固定长度的特征向量进行分类所，由于全连接层必须是固定尺寸输入，导致整个网络的输入尺寸无法改变。FCN 作者意识到了这一限制来自于网络最后的全连接层，于是将最后的全连接层改为 1×1 卷积层。\n",
    "![img](images/chapter16/transform_fc_to_conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后使用反卷积层对最后一个卷积层的特征图进行上采样，使它恢复到与输入图像相同的尺寸，从而可以对每个像素都产生一个分类输出。\n",
    "\n",
    "![img](images/chapter16/FCN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/chapter16/FCN_combine_coarse_with_fine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自从 FCN 提出后，一些经典的目标检测和识别模型都采用了 FCN 的概念，例如 Faster R-CNN 模型和 SSD 模型。 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
