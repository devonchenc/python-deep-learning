{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度卷积网络模型\n",
    "\n",
    "卷积神经网络是第一个解决重要商业应用的神经网络，并且仍然是当今深度学习商业应用的前沿，迄今为止已经提出了各种网络结构。经典卷积神经网络模型有：\n",
    "\n",
    "- LeNet-5\n",
    "- AlexNet\n",
    "- VGG\n",
    "- ResNet\n",
    "- DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "\n",
    "在 20 世纪 90 年代， 以 Yann Lecun 为首的 AT&T 神经网络研究小组开发了一个用于识别手写数字的卷积网络 LeNet-5，用来识别支票上的手写数字。它有连续的卷积层和下采样层，最后经全连接层输出预测结果。\n",
    "\n",
    "输入层输入原始图像，原始图像的分辨率为 32×32个像素。然后，后面的隐藏层在卷积和下采样之间交替进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/chapter14/LeNet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- C1 层是卷积层，卷积核尺寸为 5x5，输出了六个特征图（feature map），每个特征图尺寸是 28x28。参数个数为 $(5\\times5+1)\\times6=156$\n",
    "\n",
    "- S2 层是下采样层，它将局部像素值平均化来实现下采样。参数个数为 $2\\times6=12$\n",
    "\n",
    "![img](images/chapter14/LeNet_subsampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- C3 层是卷积层，有 16 个卷积核，卷积核尺寸为 5×5，参数个数为 $1516$。需要注意的是，C3 与 S2 并不是全连接而是部分连接，C3 的特征图有些与 S2 三层特征图连接、有些四层、甚至达到6层，目的是通过这种方式提取更多特征，连接的规则如下表所示：\n",
    "\n",
    "![img](images/chapter14/LeNet_conv.png)\n",
    "\n",
    "- S4 层与 S2 层一样，也是下采样层，参数个数为 $16\\times2 = 32$\n",
    "\n",
    "- C5 层为卷积层，卷积核尺寸为 5×5，输出图像的宽高尺寸为 $(1,1)$，输出恰好可以视为一维向量。该层参数个数为 $(16\\times5\\times5+1)\\times120=48120$\n",
    "\n",
    "- F6 层为全连接层，包含 84 个神经元，参数个数为 $(120+1)\\times84=10164$\n",
    "\n",
    "- Output 层也是全连接层，包含 10 个神经元，分别代表数字 0 到 9 的预测输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5共包含约六万个可训练网络参数，和现在的卷积神经网络相比，LeNet-5 有几个不同点：\n",
    "\n",
    "- 激活函数\n",
    "\n",
    "      LeNet 中使用 sigmoid 函数，而现在的 CNN 中主要使用 ReLU 函数\n",
    "- 下采样\n",
    "\n",
    "      原始的 LeNet 中使用下采样（Subsampling）缩小中间数据的大小，而现在的 CNN 中使用池化是主流\n",
    "\n",
    "由于当时缺乏大规模训练数据，计算机的计算能力较弱，LeNet-5 应用于其它复杂问题的处理结果并不理想。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. [AlexNet](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 出现在上个世纪九十年代，虽然展现了卷积神经网络的强大特征提取能力，但是迫于计算能力匮乏以及种种复杂的现实场景限制，只能在一些特定领域应用。同时，随着 SVM 等手工设计特征的机器学习算法飞速发展，LeNet-5 并没有形成广泛的应用。\n",
    "\n",
    "随着 ReLU 与 Dropout 的提出，以及 GPU 带来算力突破和互联网时代大数据的爆发，卷积神经网络带来历史的突破，AlexNet 网络的提出让深度学习走上人工智能的最前端。AlexNet 网络的作者是多伦多大学的 Alex Krizhevsky, Ilya Sutskever, **Geoffrey Hinton**，该网络在 2012 年的 ImageNet ILSVRC 图像识别竞赛中取得冠军，识别正确率领先第二名近 10%。\n",
    "\n",
    "AlexNet 模型共有八层结构，其中前五层为卷积层，其中前两个卷积层和第五个卷积层有池化层，最后三层为全连接层，整个网络模型共包含约六十五万个神经元，所需要训练的参数约 6000 万个。\n",
    "\n",
    "![img](images/chapter14/AlexNet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 神经网络的输入图像尺寸为 224×224×3\n",
    "\n",
    "\n",
    "- 第一层：卷积层1，卷积核尺寸为 11×11，填充 padding = 2，步长 stride 为4，卷积核的数量为 96（两块 GPU 分别计算 48 个核），输出图像分辨率为 55×55×96。然后接最大池化层，pool_size = (3, 3), stride = 2（带重叠的池化，Overlapping Pooling），输出图像分辨率为 27×27×96\n",
    "\n",
    "\n",
    "- 第二层：卷积层2，卷积核尺寸为 5×5，padding = 2, stride = 1，卷积核的数量为 256（两块 GPU 分别计算 128 个核），输出图像分辨率为 27×27×256。然后做 LRN（Local Response Normalization，局部响应归一化），再接最大池化层，pool_size = (3, 3), stride = 2，输出图像分辨率为 13×13×256\n",
    "\n",
    "\n",
    "- 第三层：卷积层3，卷积核尺寸为 3×3，padding = 1，卷积核的数量为 384（两块 GPU 分别计算 192 个核），输出图像分辨率为 13×13×384\n",
    "\n",
    "\n",
    "- 第四层：卷积层4，卷积核尺寸为 3×3，padding = 1，卷积核的数量为 384（两块 GPU 分别计算 192 个核），输出图像分辨率为 13×13×384\n",
    "\n",
    "\n",
    "- 第五层：卷积层5，卷积核尺寸为 3×3，padding = 1，卷积核的数量为 256（两块 GPU 分别计算 128 个核），输出图像分辨率为 13×13×256。然后接最大池化层，pool_size = (3, 3), stride = 2，输出图像分辨率为 6×6×256（共 9216 个神经元）\n",
    "\n",
    "\n",
    "- 第六七八层是全连接层，前两层每一层的神经元的个数为 4096，最后一层神经元个数为 1000\n",
    "\n",
    "将原文中基于两块 GPU 实现的网络结构变为单 GPU，如下图所示\n",
    "\n",
    "![img](images/chapter14/AlexNet_single_GPU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet 网络的特点：\n",
    "\n",
    "- 成功使用 ReLU 激活函数，客服了 Sigmoid 在网络较深时的梯度消失现象\n",
    "\n",
    "\n",
    "- 使用了Dropout，p=0.5，可以防止过拟合\n",
    "\n",
    "\n",
    "- 大量使用数据增强技术（从256×256原始图像中裁剪出224×224图像，再配合上水平镜像，可以达到 **2048** 倍训练数据）\n",
    "\n",
    "\n",
    "- 使用 LRN 层（目前不再使用）\n",
    "\n",
    "\n",
    "- 使用两块GPU，分两组进行卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. [VGGNet](https://arxiv.org/abs/1409.1556)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet 网络模型中局部响应归一化浪费了计算资源，但是对性能却没有很大的提升。\n",
    "\n",
    "牛津大学的视觉几何组提出的 VGGNet 的实质是 AlexNet 结构的增强版，它侧重强调卷积神经网络设计中的深度，将卷积层的深度提升到了16/19层，并且在 2014 年的 ImageNet ILSVRC 大赛中的物体检测问题中获得第一名。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 网络专注于构建卷积层的简单网络，全部采用更小的 3×3 卷积核，而不是 AlexNet 中的 11×11 卷积核。两个连续的 3×3 的卷积核相当于 5×5 的感受野，三个 3×3 的连续的卷积核相当于 7×7 的感受野。\n",
    "\n",
    "![img](images/chapter14/VGG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，网络 D 也就是通常所说的 VGG 16 网络模型，也可以绘制成下图\n",
    "\n",
    "![img](images/chapter14/VGG16.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络参数数量（单位：百万）：\n",
    "\n",
    "|网络模型|A |A-LR|B|C|D|E|\n",
    "|--|--|--|--|--|--|--|\n",
    "|参数数量|133|133|133|134|138|144|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|名称|类型|参数|输出图像尺寸|参数数量|\n",
    "|--|--|--|--|--|\n",
    "|Input|输入层||224×224×3|0|\n",
    "|CONV 64|**卷积层**|k=3,s=1,p=1|224×224×64|(3×3×3+1)×64=1,792|\n",
    "|CONV 64|**卷积层**|k=3,s=1,p=1|224×224×64|(3×3×64+1)×64=36,928|\n",
    "|POOL 2|池化层|k=2,s=2|112×112×64|0|\n",
    "|CONV 128|**卷积层**|k=3,s=1,p=1|112×112×128|(3×3×64+1)×128=73,856|\n",
    "|CONV 128|**卷积层**|k=3,s=1,p=1|112×112×128|(3×3×128+1)×128=147,584|\n",
    "|POOL 2|池化层|k=2,s=2|56×56×128|0|\n",
    "|CONV 256|**卷积层**|k=3,s=1,p=1|56×56×256|(3×3×128+1)×256=295,168|\n",
    "|CONV 256|**卷积层**|k=3,s=1,p=1|56×56×256|(3×3×256+1)×256=590,080|\n",
    "|CONV 256|**卷积层**|k=3,s=1,p=1|56×56×256|(3×3×256+1)×256=590,080|\n",
    "|POOL 2|池化层|k=2,s=2|28×28×256|0|\n",
    "|CONV 512|**卷积层**|k=3,s=1,p=1|28×28×512|(3×3×256+1)×512=1,180,160|\n",
    "|CONV 512|**卷积层**|k=3,s=1,p=1|28×28×512|(3×3×512+1)×512=2,359,808|\n",
    "|CONV 512|**卷积层**|k=3,s=1,p=1|28×28×512|(3×3×512+1)×512=2,359,808|\n",
    "|POOL 2|池化层|k=2,s=2|14×14×512|0|\n",
    "|CONV 512|**卷积层**|k=3,s=1,p=1|14×14×512|(3×3×512+1)×512=2,359,808|\n",
    "|CONV 512|**卷积层**|k=3,s=1,p=1|14×14×512|(3×3×512+1)×512=2,359,808|\n",
    "|CONV 512|**卷积层**|k=3,s=1,p=1|14×14×512|(3×3×512+1)×512=2,359,808|\n",
    "|POOL 2|池化层|k=2,s=2|7×7×512|0|\n",
    "|FC|**全连接层**|4096|4096|**(7×7×512+1)×4096=102,764,544**|\n",
    "|FC|**全连接层**|4094|4096|(4096+1)×4096=16,781,312|\n",
    "|FC|**全连接层**|1000|4096|(4096+1)×1000=4,097,000|\n",
    "|||||总数：138,357,544|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 网络的特点：\n",
    "\n",
    "- 取消了局部响应归一化层\n",
    "\n",
    "\n",
    "- 网络结构规整\n",
    "\n",
    "\n",
    "- 使用 3×3 卷积核，多个小滤波器卷积层的叠加比一个大滤波器卷积层效果好\n",
    "\n",
    "\n",
    "- 每使用一次池化层，特征图通道数翻倍\n",
    "\n",
    "\n",
    "- 验证了通过不断加深网络结构可以提升性能\n",
    "\n",
    "\n",
    "- 迁移到其它数据集时泛化性能好\n",
    "\n",
    "\n",
    "- 模型参数数量非常庞大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. [GoogLeNet](https://arxiv.org/abs/1409.4842)\n",
    "\n",
    "神经网络除了纵向的扩展，是否能进行横向的拓展？在传统的转换网络中，每个层从前一层提取信息，以便从输入数据中提取更丰富的特征表示。然而，每个层类型提取不同种类的信息，例如 5×5 卷积核的输出与 3×3 卷积核的输出不同的特征图。在任何给定的层面，我们如何知道哪种转换提供了最有用的信息？ \n",
    "\n",
    "Google 于 2014年 ILSVRC 大赛凭借 GoogleNet 获得图像分类问题的冠军，这个网络模型通过同时增加卷积神经网络的深度和宽度获得了更好地效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet 模型使用 **Inception** 模块来代替简单的卷积层。Inception 模块将 CNN 中常用的卷积运算（1x1，3x3，5x5）和池化操作拼接在一起（卷积、池化后的尺寸相同，将通道相加）。采用不同大小的卷积核意味着不同大小的感受野，拼接意味着不同尺度特征的融合。因此，Inception 模块一方面增加了网络的宽度，另一方面也增加了网络对尺度的适应性。\n",
    "![img](images/chapter14/inception_naive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而原始版本 Inception 中所有的卷积核都对上一层的所有特征图来做，而 5x5 的卷积核所需的计算量太大。为了避免这种情况，在 3x3 卷积、5x5 卷积层之前和 max pooling 层之后分别加上了 1x1 的卷积层，以起到了降低特征图数量的作用。这也就形成了 Inception v1的网络结构，如下图所示：\n",
    "\n",
    "![img](images/chapter14/inception.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于 Inception 模块构建了 GoogLeNet 的网络结构共22层，如下所示\n",
    "\n",
    "![img](images/chapter14/GoogLeNet.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet 网络的特点：\n",
    "\n",
    "- Inception 模块融合了不同尺度的特征图\n",
    "\n",
    "\n",
    "- 使用 1x1 卷积核降低维度\n",
    "\n",
    "\n",
    "- 网络采用了模块化的结构，方便增添和修改\n",
    "\n",
    "\n",
    "- 为了避免梯度消失，网络额外增加了2个辅助的 softmax 输出用于向前传导梯度\n",
    "\n",
    "\n",
    "- 网络不断发展，后续进化出更加强大的 Inception [V2](https://arxiv.org/abs/1502.03167), [V3](https://arxiv.org/abs/1512.00567), [V4](https://arxiv.org/abs/1602.07261) 版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
