{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度卷积网络模型\n",
    "\n",
    "卷积神经网络是第一个解决重要商业应用的神经网络，并且仍然是当今深度学习商业应用的前沿，迄今为止已经提出了各种网络结构。经典卷积神经网络模型有：\n",
    "\n",
    "- LeNet-5\n",
    "- AlexNet\n",
    "- VGG\n",
    "- ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "\n",
    "在 20 世纪 90 年代， 以 Yann Lecun 为首的 AT&T 神经网络研究小组开发了一个用于识别手写数字的卷积网络 LeNet-5，用来识别支票上的手写数字。它有连续的卷积层和下采样层，最后经全连接层输出预测结果。\n",
    "\n",
    "输入层输入原始图像，原始图像的分辨率为 32×32个像素。然后，后面的隐藏层在卷积和下采样之间交替进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/chapter14/LeNet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- C1 层是卷积层，卷积核尺寸为 5x5，输出了六个特征图（feature map），每个特征图尺寸是 28x28。参数个数为 $(5*5+1)*6=156$\n",
    "\n",
    "- S2 层是下采样层，它将局部像素值平均化来实现下采样。参数个数为 $2*6=12$\n",
    "\n",
    "![img](images/chapter14/LeNet_subsampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- C3 层是卷积层，有 16 个卷积核，卷积核尺寸为 5×5，参数个数为 $1516$。需要注意的是，C3 与 S2 并不是全连接而是部分连接，C3 的特征图有些与 S2 三层特征图连接、有些四层、甚至达到6层，目的是通过这种方式提取更多特征，连接的规则如下表所示：\n",
    "\n",
    "![img](images/chapter14/LeNet_conv.png)\n",
    "\n",
    "- S4 层与 S2 层一样，也是下采样层，参数个数为 $16*2 = 32$\n",
    "\n",
    "- C5 层为卷积层，卷积核尺寸为 5×5，输出图像的宽高尺寸为 $(1,1)$，输出恰好可以视为一维向量。该层参数个数为 $(16*5*5+1)*120=48120$\n",
    "\n",
    "- F6 层为全连接层，包含 84 个神经元，参数个数为 $(120+1)*84=10164$\n",
    "\n",
    "- Output 层也是全连接层，包含 10 个神经元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5共包含约六万个可训练网络参数，和现在的卷积神经网络相比，LeNet-5 有几个不同点：\n",
    "\n",
    "- 激活函数\n",
    "\n",
    "      LeNet 中使用 sigmoid 函数，而现在的 CNN 中主要使用 ReLU 函数\n",
    "- 下采样\n",
    "\n",
    "      原始的 LeNet 中使用下采样（Subsampling）缩小中间数据的大小，而现在的 CNN 中使用池化是主流\n",
    "\n",
    "由于当时缺乏大规模训练数据，计算机的计算能力较弱，LeNet-5 应用于其它复杂问题的处理结果并不理想。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. [AlexNet](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 出现在上个世纪九十年代，虽然展现了卷积神经网络的强大特征提取能力，但是迫于计算能力匮乏以及种种复杂的现实场景限制，只能在一些特定领域应用。同时，随着 SVM 等手工设计特征的机器学习算法飞速发展，LeNet-5 并没有形成广泛的应用。\n",
    "\n",
    "随着 ReLU 与 Dropout 的提出，以及 GPU 带来算力突破和互联网时代大数据的爆发，卷积神经网络带来历史的突破，AlexNet 的提出让深度学习走上人工智能的最前端。AlexNet 网络在 2012 年的 ImageNet 图像识别竞赛中取得冠军，赛后整理发表的文章是\"ImageNet Classification with Deep Convolutional Neural Networks\"，作者为多伦多大学的 Alex Krizhevsky, Ilya Sutskever, **Geoffrey Hinton**。\n",
    "\n",
    "AlexNet模型共有8层结构，其中前5层为卷积层，其中前两个卷积层和第五个卷积层有池化层。最后 3 层为全连接层，整个网络模型共包含约六十五万个神经元，所需要训练的参数约六千万个。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet 网络的特点：\n",
    "\n",
    "- 第一次使用 ReLU 激活函数，有更好的梯度特性、训练更快。\n",
    "- 使用了随机失活(dropout)，p=0.5，可以防止过拟合\n",
    "- 大量使用数据增强技术\n",
    "- 使用SGD，Momentum 0.9\n",
    "- learning rate 1e-2 (0.01)， reduced by 10 manually when val accuracy plateaus\n",
    "- L2 weight decay 5e-4\n",
    "- Batch size 128\n",
    "- 使用Norm layers（不再使用）\n",
    "- 使用两块GPU，分两组进行卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
